# 操作系统
# 概述
## 操作系统的特点
* 并发性
	
	并发指宏观上在一段时间内能运行多个程序，并行指同一时刻能运行多个指令
	
* 共享性
	
	**系统中的资源可以被多个并发进程共同使用**。互斥共享和同时共享
	
* 虚拟性
	
	**虚拟技术把一个物理实体转为多个逻辑实体**。时分复用和空分复用。  
	
	多个进程在同一处理器上并发执行使用了时分复用；**虚拟内存使用了空分复用，它将物理内存抽象为地址空间，每个进程有各自的地址空间**。地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内存中。  
	
* 异步
	
	进程不是一次执行完毕，而是走走停停，以不可知的速度向前推进。

## 系统调用
如果一个进程在用户态需要使用内核态的功能，就进行系统调用从而**陷入内核**，由操作系统代为完成。  

Linux的系统调用主要有：

|Task|Commands|
|----|----|
|进程控制|fork(); exit(); wait();|
|进程通信|pipe(); shmget(); mmap();|
|文件操作|open(); read(); write()|
|设备操作|ioctl(); read(); write()|
|信息维护|getpid(); alarm(); sleep()|
|安全|chmod(); umask(); chown()|

## 宏内核和微内核
1. 宏内核是将操作系统功能作为一个紧密结合的整体放到内核，由于各模块共享信息，因此有很高的性能
2. 微内核：由于操作系统不断复杂，将一部分功能一处内核。移出的部分根据分层原则划分为若干服务，相互独立。
	在微内核架构下，操作系统被划分成小的，定义良好的模块，只有微内核这一个模块运行在内核态，其余模块运行在用户态。
	因为需要频繁在用户态和内核态之间切换，会有一定的性能损失。

## 中断分类
1. 外中断：由 CPU 执行指令以外的事件引起，如 I/O 完成中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断等。
2. 异常：由 CPU 执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等。
3. 陷入：在用户程序中使用系统调用。

# 进程
## 进程
1. 进程指**系统中正在运行的一个应用程序，程序一旦运行就是进程**
2. 进程可以认为是**程序执行的一个实例**，操作系统**进行资源分配的最小单位**，且每个进程拥有**独立的地址空间**
3. **进程是资源分配的基本单位**
3. 一个进程无法直接访问另一个进程的变量和数据结构，如果希望访问另一个进程的资源，需要使用进程间通信，如：管道、消息队列等
4. 线程是进程的一个实体，是进程的一条执行路径；比进程更小的独立运行的基本单位，线程也被称为轻量级进程，一个程序至少有一个进程，一个进程至少有一个线程
5. 进程有**运行、阻塞、就绪**三个基本状态
6. 进程调度算法：先来先服务、短作业优先、非抢占式优先级调度、抢占式优先级调度、高响应比、时间片轮转法

## 线程
1. **线程是独立调度的基本单位**
2. 一个进程中可以有多个线程，它们共享进程资源

## 进程与线程的区别
1. **拥有资源**
	
	进程是**资源分配**的基本单位，但**线程不拥有资源，线程可以访问隶属进程的资源**
	
2. **调度**

  线程是**独立调度**的基本单位，在同一进程中，线程切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换

3. **系统开销**

    创建或撤销进程时，系统都要分配或回收资源，如内存空间、I/O设备等，所付出的开销远大于创建或撤销线程时的开销。

    类似的，**在进程切换时，涉及当前执行进程CPU环境的保存和新调度进程CPU环境的设置，开销很大；而线程切换时只需保存和设置少量寄存器内容，开销很小。**

4. **通信**

  线程间可以通过**直接读写同一进程中的数据进行通信**；但**进程通信需要借助IPC**

## 线程和协程之间的区别

1. **管理**

   线程被操作系统内核所管理，而协程直接被应用程序所控制，所以协程的性能提升很大，不会像线程切换那样陷入内核态消耗极大资源。  

2. 

## 进程状态的切换
![进程状态切换](./Pics/进程状态切换.png)  

* 就绪状态（ready）：等待被调度
* 运行状态（running）
* 阻塞状态（waiting）：等待资源

注意：
* 只有就绪态和运行态可以互相切换，其他都是单向转换。就绪态的进程通过调度算法从而获得CPU事件，转为运行态；运行态在分配给他的CPU时间片用完后转为就绪态，等待下一次调度
* 阻塞状态是缺少需要的资源而从运行态转换而来，但该资源不包括CPU时间。缺少CPU时间会转为就绪态而非阻塞态

## 进程调度算法
不同环境的调度算法目标不同，需要针对不同环境来讨论调度算法
### 批处理系统
批处理系统没有太多用户操作，在该系统中，调度算法目标是**保证吞吐量和周转时间**
1. **先来先服务 first-come first-serverd（FCFS）**
	非抢占式的调度算法，按照请求的顺序进行调度。
	有利于长作业，不利于短作业。短作业需要等待前面的长作业执行完毕才能执行，造成等待时间过长。

2. **短作业优先 shortest job first（SJF）**
	非抢占式的调度算法，按估计运行时间最短的顺序进行调度。
	长作业可能会被饿死，如果一直有短作业导来，那么长作业永远得不到调度，处于一直等待短作业执行完毕的状态。
	
3. **最短剩余时间优先 shortest remaining time next（SRTN）**
	抢占式版本的短作业优先。按剩余运行时间的顺序调度。当新作业到达时，其整个运行时间与当前进程剩余时间作比较，如果新作业需要的时间更少，则挂起当前进程，运行新进程。否则新进程等待。
### 交互式系统
交互式系统有大量的用户交互操作，在该系统中，调度算法的目标是**快速的响应**
1. **时间片轮转**
	
	将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，**由计时器发出时钟中断**，调度程序便停止该进程的执行，并将它**送往就绪队列的末尾**，同时继续把 CPU 时间分配给队首的进程。
	
	时间片轮转算法的效率和时间片大小有很大关系：

	* 如果时间片太小，会导致进程切换太频繁，开销太大。进程切换需要保存进程信息并载入新进程的信息。
	* 如果时间片过长，实时性就不能得到保证
	
2. **优先级调度**

  为每个进程分配一个优先级，按优先级进行调度。

  为防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级

3. **多级反馈队列**

  一个进程需要执行100个时间片，如果采用时间片轮转，那么需要交换100次。  

  多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如1，2，4，8，…。进程在第一个队列没有执行完，就被移到下一个队列，在这种方式下，100个时间片的进程只需要交换7次。  

  每个队列优先权也不同，最上面的优先权最高，因此只有上一个队列没有进程在排队，才能调度当前队列的进程。

  可以将这种调度算法看成是时间片轮转和优先级的结合。  
### 实时系统
实时系统要求一个请求在一个确定时间内得到响应。  

分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。  

## 进程同步
### 1. **临界区**

虽然多个进程可以共享系统中的各种资源，**但其中许多资源一次只能为一个进程所使用，我们把一次仅允许一个进程使用的资源称为临界资源。**  

许多物理设备都属于临界资源，如打印机等。此外，还有许多变量、数据等都可以被若干进程共享，也属于临界资源。

对临界资源进行访问的那段代码称为临界区  	

为了互斥访问临界资源，每个进程再进入临界区之前，需要先进行检查  

### 2. **同步与互斥**
* 同步：多个进程因为合作产生的直接制约关系：使得进程有一定的先后执行关系
* 互斥：多个进程在同一时刻只有一个进程能进入临界区

https://houbb.github.io/2020/10/04/os-04-sync

### 3. **信号量**
信号量（Semaphore）是一个整型变量，可以对其执行down和up操作，也就是常见的P V 操作  
* down：如果信号量大于0，执行-1操作；如果信号量等于0，进程睡眠，等待信号量大于0
* up：对信号量执行 + 1操作，唤醒睡眠的进程让其完成down操作

down和up操作需要被设计成原语，不可分割，通常做法是在执行这些操作时**屏蔽中断**  

如果信号量的取值只能是0 或 1，那就成为了**互斥量Mutex**，0表示临界区已经加锁，1表示临界区解锁。  

**使用信号量实现生产者--消费者问题**  

问题描述：使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品。  

解析：因为缓冲区属于临界资源，因此需要使用一个互斥量 mutex 来控制对缓冲区的互斥访问。  

为了同步生产者和消费者的行为，需要记录缓冲区中物品的数量。数量可以使用信号量来进行统计，这里需要使用两个信号量：empty 记录空缓冲区的数量，full 记录满缓冲区的数量。其中，empty 信号量是在生产者进程中使用，当 empty 不为 0 时，生产者才可以放入物品；full 信号量是在消费者进程中使用，当 full 信号量不为 0 时，消费者才可以取走物品。  

注意，**不能先对缓冲区进行加锁，再测试信号量**。也就是说，不能先执行 down(mutex) 再执行 down(empty)。如果这么做了，那么可能会出现这种情况：生产者对缓冲区加锁后，执行 down(empty) 操作，发现 empty = 0，**此时生产者睡眠**。消费者不能进入临界区，因为生产者对缓冲区加锁了，消费者就无法执行 up(empty) 操作，empty 永远都为 0，导致生产者永远等待下，不会释放锁，消费者因此也会永远等待下去。  

```
#define N 100
typedef int semaphore;
semaphore mutex = 1;
semaphore empty = N;
semaphore full = 0;

void producer() {
	while(TRUE) {
		int item = produce_item();
		down(&empty);
		down(&mutex);
		insert_item(item);
		up(&mutex);
		up(&full);
	}
}

void consumer() {
	while(TRUE) {
		down(&full);
		down(&mutex);
		int item = remove_item();
		consume_item(item);
		up(&mutex);
		up(&empty);
	}
}
```

### 4. 管程
使用信号量机制实现生产者-消费者问题需要客户端代码做很多控制，而管程把控制的代码独立出来，不仅不容易出错，也使得客户端代码调用更容易  

```
monitor ProducerConsumer
	integer i;
	condition c;
	
	procedure insert();
	begin
		// ...
	end;
	
	    procedure remove();
    begin
        // ...
    end;
end monitor;
```

管程有一个重要特性：**在一个时刻只能有一个进程使用管程。进程在无法继续执行的时候不能一直占用管程，否则其它进程永远不能使用管程。**  

管程引入了 条件变量 以及相关的操作：**wait() 和 signal() 来实现同步操作**。对条件变量执行 wait() 操作会导致调用进程阻塞，把管程让出来给另一个进程持有。signal() 操作用于唤醒被阻塞的进程。（Java中 syncronized和wait()/notify()操作都是管程）  
```
monitor ProducerConsumer
	condition full, empty;
	integer count := 0;
	condition c;
	
	procedure insert(item: integer);
	begin
		if count = N then wait(full);
		insert_item(item);
		count := count + 1;
		if count = 1 then signal(empty);
	end;
	
	function remove: integer;
	begin
		if count = 0 then wait(empty);
		remove = remove_item;
		count := count - 1;
		if count = N -1 then signal(full);
	end;
end monitor;


// 生产者客户端
procedure producer
begin
    while true do
    begin
        item = produce_item;
        ProducerConsumer.insert(item);
    end
end;

// 消费者客户端
procedure consumer
begin
    while true do
    begin
        item = ProducerConsumer.remove;
        consume_item(item);
    end
end;
```

## 经典同步问题
### 1. 生产者消费者问题
前面已经说过了
### 2. 哲学家进餐问题
![哲学家进餐问题](./Pics/哲学家进餐问题.jpg)
五个哲学家围着一张圆桌，每个哲学家面前放着食物。哲学家的生活有两种交替活动：吃饭以及思考。当一个哲学家吃饭时，需要先拿起自己左右两边的两根筷子，并且一次只能拿起一根筷子。

* 一种错误做法：如果所有哲学家同时拿起左手边的筷子，那么所有哲学家都在等待其它哲学家吃完并释放自己手中的筷子，导致死锁。

为了防止死锁发生，可以设置两个条件：
* 必须同时拿起左右两根筷子
* 只有在两个邻居都没有进餐的情况下才允许进餐  

```
#define N 5					 //哲学家数量
#define LEFT (i + N - 1) % N // 左邻居
#define RIGHT (i + 1) % N    // 右邻居
#define THINKING 0
#define HUNGRY   1
#define EATING   2
typedef int semaphore;
int state[N];                // 跟踪每个哲学家的状态
semaphore mutex = 1;         // 临界区的互斥，临界区是 state 数组，对其修改需要互斥
semaphore s[N];              // 每个哲学家一个信号量

void philosopher(int i) {
	while (TRUE) {
		think(i);
		take_two(i);
		eat(i);
		put_two(i);
	}
}

void take_two(int i) {
	down(&mutex);
	state[i] = HUNGRY;
	check(i);
	up(&mutex);
	down(&s[i]); // 只有收到通知之后才可以开始吃，否则会一直等下去
}

void put_two(i) {
    down(&mutex);
    state[i] = THINKING;
    check(LEFT); // 尝试通知左右邻居，自己吃完了，你们可以开始吃了
    check(RIGHT);
    up(&mutex);
}

void eat(int i) {
    down(&mutex);
    state[i] = EATING;
    up(&mutex);
}

// 检查两个邻居是否都没有用餐，如果是的话，就 up(&s[i])，使得 down(&s[i]) 能够得到通知并继续执行
void check(i) {         
    if(state[i] == HUNGRY && state[LEFT] != EATING && state[RIGHT] !=EATING) {
        state[i] = EATING;
        up(&s[i]);
    }
}
```
**我感觉上面代码有点问题**，换下面这个  

原理：**仅当一个哲学家的左右两支筷子都可用时** ，才允许他拿起筷子进餐。可以利用AND 型信号量机制实现，也可以利用信号量的保护机制实现。利用信号量的保护机制实现的思想是通过记录型信号量mutex对取左侧和右侧筷子的操作进行保护，使之成为一个原子操作，这样可以防止死锁的出现。描述如下：
```
semaphore chopstick[5]={1,1,1,1,1};
void philosopher(int i)
{
	while(true)
	{
		/* 这个过程中可能只能由一个人在吃饭 */
		think();
		wait(mutex); // 保护信号量
		wait(chopstick[(i+1)%5]); // 请求右手边的筷子
		wait(chopstick[i]); // 请求左手边的筷子
		signal(mutex); // 释放保护信号量
		eat();
		signal(chopstick[(i+1)%5]); // 释放右手边的筷子
		signal(chopstick[i]); // 释放左手边的筷子
	}
} 
```


### 3. 读者写者问题
允许多个进程同时对数据进行读操作，但不允许读和写，写和写操作同时发生  

一个整型变量count记录在对数据进行读操作的进程数量，一个互斥量count_mutex用于对count加锁，一个互斥量data_mutex用于对读写的数据加锁。  

```
typedef int semaphore;
semaphore count_mutex = 1;
semaphore data_mutex = 1;
int count = 0;

void reader() {
	while (TRUE) {
		down(&count_mutex);
		count++;
		if (count == 1) down(&data_mutex);// 第一个读者需要对数据进行加锁，防止写进程访问
		up(&count_mutex);
		read();
		down(&count_mutex);
		count--;
		if (count == 0) up(&data_mutex);// 最后一个退出的读者需要对数据进行解锁，以允许写进程访问
		up(&count_mutex);
	}
}

void writer() {
	while(TRUE) {
		down(&data_mutex);
		write();
		up(&data_mutex);
	}
}
```

## 进程通信
* 进程同步：控制多个进程按一定顺序执行

* 进程通信：进程间传输信息

  进程通信是一种手段，而进程同步是一种目的。也可以说，为了能够达到进程同步的目的，需要让进程进行通信，传输一些进程同步所需要的信息。  

### 1. 管道
管道是通过调用pipe函数创建的，fd[0]用于读，fd[1]用于写
```
#include <unistd.h>
int pipe(int fd[2]);
```
它具有以下限制：
* 只支持半双工通信

* 只能在父子进程或者兄弟进程中使用  

![管道](./Pics/管道.png)  

### 2. FIFO
也称为命名管道，去除了管道只能在父子进程中使用的限制。  

```
#include <sys/stat.h>
int mkfifo(const char *path, mode_t mode);
int mkfifoat(int fd, const char *path, mode_t mode);
```
FIFO 常用于客户-服务器应用程序中，FIFO 用作汇聚点，在客户进程和服务器进程之间传递数据。  

![FIFO](./Pcis/FIFO.png)    

### 3. 消息队列

> msgget msgsnd msgrcv msgctl等函数

相比于FIFO，消息队列具有以下优点：

* 消息队列可以独立于读写进程，避免了FIFO中同步管道的打开和关闭时可能产生的困难  
* 避免了FIFO的同步阻塞问题，不需要进程自己提供同步方法
* 都进程可以根据消息类型有选择的接收消息，而不像FIFO那样只能默认接受

### 4. 信号量
它是一个计数器，用于为多个进程提供共享数据对象的访问

### 5. 共享存储

https://blog.csdn.net/ljianhui/article/details/10253345  

允许多个进程共享一个给定的存储区。因为数据不需要在进程之间复制，所以这是**最快**的一种 IPC。  

需要使用信号量用来同步对共享存储的访问。  

多个进程可以将同一个文件映射到它们的地址空间从而实现共享内存。另外 XSI 共享内存不是使用文件，而是使用内存的匿名段。  

### 6. 套接字
与其他通信机制不同的是，它可以用于不同机器间的进程通信。  

# 死锁
## 必要条件
* **互斥**：每个资源要么已经分配给了一个进程，要么就是可用的
* **占有和等待**：已经得到了某个资源的进程可以再请求新的资源
* **不可抢占**：已经分配给一个进程的资源不能强制性的被抢占，它只能被占有它的进程显示的释放
* **环路等待**：有两个或者两个以上的进程组成一条环路，该环路上每个进程都在等待下一个进程所占有的资源

## 处理方法
主要有以下四种：
* 鸵鸟策略
* 死锁检测与死锁恢复
* 死锁预防
* 死锁避免

## 鸵鸟策略
把头埋在沙子里，假装没发生死锁问题  

因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。  

当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。  

大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它。   

## 死锁检测与死锁恢复
不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。  
### 1. 每种类型一个资源的死锁检测
![每种类型一个资源的死锁检测](./Pics/每种类型一个资源的死锁检测.png)  
上图为资源分配图，其中方框表示资源，圆圈表示进程。资源指向进程表示该资源已经分配给该进程，进程指向资源表示进程请求获取该资源。

图 a 可以抽取出环，如图 b，它满足了环路等待条件，因此会发生死锁。

每种类型一个资源的死锁检测算法是**通过检测有向图是否存在环**来实现，从一个节点出发进行**深度优先搜索**，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有向图存在环，也就是检测到死锁的发生。

### 2. 每种类型多个资源的死锁检测
![每种类型多个资源的死锁检测](./Pics/每种类型多个资源的死锁检测.png)  
* E 向量：资源总量
* A 向量：资源剩余量
* C 矩阵：每个进程所拥有的资源数量，每一行都代表一个进程拥有资源的数量
* R 矩阵：每个进程请求的资源数量

进程 P1 和 P2 所请求的资源都得不到满足，只有进程 P3 可以，让 P3 执行，之后释放 P3 拥有的资源，此时 A = (2 2 2 0)。P2 可以执行，执行后释放 P2 拥有的资源，A = (4 2 2 1) 。P1 也可以执行。所有进程都可以顺利执行，没有死锁。  

算法总结：

每个进程最开始时都不被标记，执行过程有可能被标记。当算法结束时，任何没有被标记的进程都是死锁进程。  

1. 寻找一个没有标记的进程P<sub>i</sub>，它所请求的资源小于等于A
2. 如果找到了这样一个进程，那么C矩阵第i行加到A中，标记该进程，并转回步骤1
3. 如果没有这样一个进程，算法终止

### 3. 死锁恢复
* 利用**抢占**恢复
* 利用**回滚**恢复
* 通过**杀死进程**恢复

## 死锁预防
在**程序运行之前**预防发生死锁

### 1. 破坏互斥条件
例如”假脱机打印机“技术允许若干个进程同时输出，唯一真正请求物理打印机的进程是打印机守护进程  
### 2. 破坏占有和等待条件
一种实现方式是**规定所有进程在开始执行前要请求所需要的全部资源**  
### 3. 破坏不可抢占条件

不可抢占无法破坏，资源需要保持不可抢占

### 4. 破坏环路等待
给资源统一编号，进程只能按照编号顺序请求资源  

## 死锁避免
在**程序运行**时避免发生死锁

### 1. 安全状态
定义：如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也**仍然存在某种调度次序能够使得每一个进程运行完毕**，则称该状态是安全的。  

![安全状态](./Pics/安全状态.png)  

图 a 的第二列 Has 表示已拥有的资源数，第三列 Max 表示总共需要的资源数，Free 表示还有可以使用的资源数。从图 a 开始出发，先让 B 拥有所需的所有资源（图 b），运行结束后释放 B，此时 Free 变为 5（图 c）；接着以同样的方式运行 C 和 A，使得所有进程都能成功运行，因此可以称图 a 所示的状态时安全的。  

安全状态的检测与死锁的检测类似，因为安全状态必须要求不能发生死锁。下面的银行家算法与死锁检测算法非常类似，可以结合着做参考对比。  

### 2. 单个资源的银行家算法
一个小城镇的银行家，他向一群客户分别承诺了一定的贷款额度，算法要做的是判断对请求的满足是否会进入不安全状态，如果是，就拒绝请求；否则予以分配。  

![单个资源的银行家算法](./Pics/单个资源的银行家算法.png)  

上图 c 为不安全状态，因此算法会拒绝之前的请求，从而避免进入图 c 中的状态。  

### 3. 多个资源的银行家算法
![多个资源的银行家算法](./Pics/多个资源的银行家算法.png)  

上图中有五个进程，四个资源。左边的图表示已经分配的资源，右边的图表示还需要分配的资源。最右边的 E、P 以及 A 分别表示：总资源、已分配资源以及可用资源，注意这三个为向量，而不是具体数值，例如 A=(1020)，表示 4 个资源分别还剩下 1/0/2/0。  

检查一个状态是否安全的算法如下：

* 查找右边的矩阵是否存在一行小于等于向量 A。如果不存在这样的行，那么系统将会发生死锁，状态是不安全的。
* 假若找到这样一行，将该进程标记为终止，并将其已分配资源加到 A 中。
* 重复以上两步，直到所有进程都标记为终止，则状态时安全的。

如果一个状态不是安全的，需要拒绝进入这个状态。   

# 内存管理

## 虚拟内存

https://www.cnblogs.com/myseries/p/12487211.html  

虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。  

为了更好的管理内存，操作系统将**内存抽象成地址空间**。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一**页**。**这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中**。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，**将缺失的部分装入物理内存**并重新执行失败的指令。  

从上面的描述中可以看出，虚拟内存允许程序**不用将地址空间中的每一页都映射到物理内存，也就是说一个程序不需要全部调入内存就可以运行**，这使得**有限的内存运行大程序成为可能**。例如有一台计算机可以产生 16 位地址，那么一个程序的地址空间范围是 0~64K。该计算机只有 32KB 的物理内存，虚拟内存技术允许该计算机运行一个 64K 大小的程序。  

## 分页系统地址映射

**内存管理单元（MMU）管理着地址空间和物理内存的转换**，其中的**页表（Page table）存储着页（程序地址空间）和页框（物理内存空间）的映射表**  

一个虚拟地址分为两部分，一部分存储**页面号**，一部分存储**偏移量**。  

下图的页表存放着 16 个页，这 16 个页需要用 4 个比特位来进行索引定位。例如对于虚拟地址（0010 000000000100），前 4 位是存储页面号 2，读取表项内容为（110 1），页表项最后一位表示是否存在于内存中，1 表示存在。后 12 位存储偏移量。这个页对应的页框的地址为 （110 000000000100）。  

![分页系统地址映射](./Pics/分页系统地址映射.png)  

## 页面置换算法

在程序运行过程中，如果要访问的页面不在内存中，就发生**缺页中断从而将该页调入内存中**。此时如果内存已无空闲空间，系统必须从内存中**调出一个页面到磁盘对换区中**来腾出空间。  

**页面置换算法和缓存淘汰策略类似，可以将内存看成磁盘的缓存**。在缓存系统中，缓存的大小有限，当有新的缓存到达时，需要淘汰一部分已经存在的缓存，这样才有空间存放新的缓存数据。  

页面置换算法的主要目标是**使页面置换频率最低（也可以说缺页率最低）**。  

### 1. 最佳
> OPT, Optimal replacement algorithm

所选择的被换出的页是最长时间内不再被访问，通常可以保证获得最低的缺页率。  

**是理论上的算法，无法真正实现，因为无法知道一个页面多长时间不再被访问。  **  

举例：一个系统为某进程分配了三个物理块，并有如下页面引用序列：
```
7，0，1，2，0，3，0，4，2，3，0，3，2，1，2，0，1，7，0，1
```

开始运行时，将7，0，1三个页面装入内存，当进程要访问页面 2 时，产生缺页中断，会将页面 7 换出，因为页面 7 再次被访问的时间最长。  

### 2. 最近最少使用/最近最久未使用 - LRU

> LRU, Least Recently Used

虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU 将最近最久未使用的页面换出。  

为了实现 LRU，需要在内存中维护一个**所有页面的链表**。当一个页面被访问时，将这个页面移到**链表表头**。这样就能保证链表表尾的页面是最近最久未访问的。  

因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。  

```
4，7，0，7，1，0，1，2，1，2，6
```
![LRU](./Pics/LRU.png)  

### 3. 最近未使用 - NRU

> NRU, Not Recently Used

每个页面都有两个状态位：R 与 M，当页面被访问时设置页面的 R=1，当页面被修改时设置 M=1。其中** R 位会定时被清零**。可以将页面分成以下四类：  

* R = 0, M = 0
* R = 0, M = 1
* R = 1, M = 0
* R = 1, M = 1

当发生缺页中断，NRU算法随机地从类编号最小的非空类中挑选一个页面将他换出。  

NRU 优先换出已经被修改的脏页面（R=0，M=1），而不是被频繁使用的干净页面（R=1，M=0）。

### 4. 先进先出

选择换出的页面是最先进入的页面。  

该算法会将那些经常被访问的页面换出，导致缺页率升高。  

### 5. 第二次机会算法
FIFO 算法可能会把经常使用的页面置换出去，为了避免这一问题，对该算法做一个简单的修改：  

当页面被访问 (读或写) 时设置该页面的 R 位为 1。需要替换的时候，检查最老页面的 R 位。如果 R 位是 0，那么这个页面既老又没有被使用，可以立刻置换掉；**如果是 1，就将 R 位清 0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样**，然后继续从链表的头部开始搜索。  

### 6. 时钟
第二次机会算法需要在链表中移动页面，降低了效率。时钟算法**使用环形链表将页面连接起来**，再使用一个指针指向最老的页面。  

![Clock](./Pics/Clock.png)  

## 分段
虚拟内存采用的是分页技术，也就是**将地址空间划分成固定大小的页**，每一页再与内存进行映射。  

下图为一个编译器在编译过程中建立的多个表，有 4 个表是动态增长的，如果使用分页系统的一维地址空间，**动态增长的特点会导致覆盖问题的出现。**  

![分段](./Pics/分段.png)  

分段的做法是把每个表分成段，一个段构成一个独立的地址空间。每个段的长度可以不同，并且可以动态增长。  

![分段1](./Pics/分段1.png)  

## 段页式

程序的**地址空间划分成多个拥有独立地址空间的段，每个段上的地址空间划分成大小相同的页**。这样既拥有分段系统的共享和保护，又拥有分页系统的虚拟内存功能。  

## 分页与分段的比较

* **对程序员的透明性**：
	
	分页透明  
	
	分段需要程序员显示划分每个段
	
* **地址空间的维度**
	
	分页是一维地址空间  
	
	分段是二维地址空间  
	
* **大小是否可以改变**
	
	页的大小不可变  
	
	段的大小可以动态改变
	
* **出现的原因**
	
	分页主要用于实现虚拟内存，从而获得更大的地址空间  
	
	分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护  
# 设备管理
## 磁盘结构
* 盘面（Platter）：一个磁盘有多个盘面；
* 磁道（Track）：盘面上的圆形带状区域，一个盘面可以有多个磁道；
* 扇区（Track Sector）：磁道上的一个弧段，一个磁道可以有多个扇区，它是最小的物理储存单位，目前主要有 512 bytes 与 4 K 两种大小；
* 磁头（Head）：与盘面非常接近，能够将盘面上的磁场转换为电信号（读），或者将电信号转换为盘面的磁场（写）；
* 制动手臂（Actuator arm）：用于在磁道之间移动磁头；
* 主轴（Spindle）：使整个盘面转动。

![磁盘结构](./Pics/磁盘结构.png)  

## 磁盘调度算法

影响读写一个磁盘块的时间的因素有：
* 旋转时间（主轴转动盘面，使得磁头移动到适当的扇区上）
* 寻道时间（制动手臂移动，使得磁头移动到适当的磁道上）
* 实际的数据传输时间

**其中，寻道时间最长，因此磁盘调度的主要目标是使磁盘的平均寻道时间最短。**

### 1. 先来先服务 - FCFS
> FCFS, First Come First Served

按照磁盘请求的顺序进行调度。  

优点是公平和简单。缺点也很明显，因为**未对寻道做任何优化，使平均寻道时间可能较长。**  

### 2. 最短寻道时间优先 - SSTF

> SSTF, Shortest Seek Time First

**优先调度与当前磁头所在磁道距离最近的磁道。**

虽然平均寻道时间比较低，但是**不够公平**。如果新到达的磁道请求总是比一个在等待的磁道请求近，那么在等待的磁道请求会一直等待下去，也就是**出现饥饿现象**。具体来说，两端的磁道请求更容易出现饥饿现象。  

![最短寻道时间优先](./Pics/最短寻道时间优先.png)  

### 3. 电梯算法 - SCAN

电梯总是保持一个方向运行，知道该方向没有请求位置，然后改变运行方向。  

电梯算法（扫描算法）和电梯的运行过程类似，**总是按一个方向来进行磁盘调度，直到该方向上没有未完成的磁盘请求，然后改变方向**。  

因为考虑了移动方向，因此所有的磁盘请求都会被满足，**解决了 SSTF 的饥饿问题**。  

![电梯算法](./Pics/电梯算法.png)

###  Linux中的磁盘IO调度算法

https://www.cnblogs.com/cobbliu/p/5389556.html

#### 1. Noop

Noop是最简单的IO调度，它本质上是一个链表实现的FIFO队列，并对请求做简单的合并处理，本身并没有任何可配置的参数。 

#### 2. cfq

cfq是通用服务器较好的IO调度算法选择，绝对公平。   

CFQ为竞争块折别使用权的所有进程分配一个请求队列和一个时间片，在调度器分配给某进程的时间片内，进程可以将其读写请求发送给底层块设备，当进程的时间片消耗完，进程的请求队列将被挂起，等待调度。  

#### 3. Deadline

Deadline算法的核心在于保证每个IO请求在一定时间内一定要被服务到，以此来避免某个请求饥饿。  

Deadline引入四个队列，分为两类，每一类都由读写两类队列组成。一类队列用来对请求按照起始扇区序号进行排序，通过红黑树组织，成为sort_list；另一类对请求按照他们的生成时间排序，由链表组织，成为fifo_list。每当确定了一个传输方向（读或写），都将从sort_list中将一批连续请求dispatch到request_queue的请求队列中，具体数目由fifo_batch来确定。  

Deadline 实现了四个队列，其中两个分别处理正常的 read 和 write，按扇区号排序，进行正常 IO 的合并处理以提高吞吐量。  

因为 IO 请求可能会集中在某些磁盘位置，这样会导致新来的请求一直被合并，可能会有其他磁盘位置的 IO 请求被饿死。  

因此实现了另外两个处理超时 read 和 write 的队列，按请求创建时间排序，如果有超时的请求出现，就放进这两个队列，调度算法保证超时（达到最终期限时间）的队列中的请求会优先被处理，防止请求被饿死。    

注：在一些多线程应用和数据库应用下，Deadline比CFQ算法效果要好。  


# 链接

## 编译系统

```
gcc -o hello hello.c
```
由编译器把源文件转换为目标文件，这个过程大致如下：  

![编译系统](./Pics/编译系统.png)  

* 预处理阶段：处理以#开头的预处理命令
* 编译阶段：翻译成汇编文件
* 汇编阶段：将汇编文件翻译成可重定位目标文件
* 链接阶段：**将可重定位目标文件和 printf.o 等单独预编译好的目标文件进行合并，得到最终的可执行目标文件。**  

## 静态链接
静态链接器以一组可重定位目标文件为输入，生成一个完全链接的可执行目标文件作为输出。链接器主要完成以下两个任务：  
* 符号解析：每个符号对应于一个函数、一个全局变量或一个静态变量，符号解析的目的是**将每个符号引用与一个符号定义关联起来**。
* 重定位：链接器通过**把每个符号定义与一个内存位置关联起来**，然后修改所有对这些符号的引用，**使得它们指向这个内存位置**。

## 目标文件

* 可执行目标文件：可以直接在内存中执行；
* 可重定位目标文件：可与其它可重定位目标文件在链接阶段合并，创建一个可执行目标文件；
* 共享目标文件：这是一种特殊的可重定位目标文件，可以在运行时被动态加载进内存并链接；

## 动态链接
静态库有以下两个问题：  
* 当静态库更新时那么整个程序都要重新进行链接；
* 对于 printf 这种标准函数库，如果每个程序都要有代码，这会极大浪费资源。

**共享库是为了解决静态库的这两个问题而设计的，在 Linux 系统中通常用 .so 后缀来表示，Windows 系统上它们被称为 DLL。**它具有以下特点：  

* 在给定的文件系统中一个库只有一个文件，所有引用该库的可执行目标文件都共享这个文件，它不会被复制到引用它的可执行文件中；
* 在内存中，一个共享库的 .text 节（已编译程序的机器代码）的一个副本可以被不同的正在运行的进程共享。





